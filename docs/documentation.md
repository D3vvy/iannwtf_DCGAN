# Deep Convolutional Generative Adversarial Model

## Introduction: What is a DCGAN

Generative Adversarial Models are fairly new branch of unsupervised learning. Their goal is to generate samples (images, text, music, videos) which resembles their trainings-set. The remarkable thing is: It does **not reproduce** them; i.e. it generates images which were never there before.

To dive further into the topic and our implementation of, let's cover the basics first.

#### Basics 1: What is a Generative Model
Like it was said before, generativ models are able to randomly generate observable data values. Let's assume a generative Model **g** is trained on a training data **X** sampled from a true distribution **D**. If, after the training is complete, we provide **g** with some standard random distribution **Z** it will produce a distribution **D'** which is supposed to (more or less) closely resemble **D**.
The convenient way to determine **g** involes a maximum likelihood estimation and further complex caculations.

#### Basics 2: What is a Generative Adversarial Model
By using an adversarial training process we can have an elegent way of avoiding these convoluted calculations. The idea is that instead of having only a generating Model **g** called the **Generator**, we also bring a discriminating Model **d** in the playing field which is called the **Discriminator**.
Assuming our training data **X** is sampled from a Distribution **D_d**, after training **g** is able map random input **D<sup>n</sup> ==> D<sup>d</sup>**. It will try to make those samples as "good" as realistic as possible.
The discriminator **d**'s task is to map **D<sup>d</sup> ==> {0,1}**. It will get real samples from **X** and "fake" samples **X<sub>fake</sub>** generated by **g** and try to discriminate them by ideally labeling all samples **X** with 1 and all samples **X<sub>fake</sub>** with 0.
The reason for having these 2 models is to put them up against each other, i.e. **d** will try to "filter out" all generated sample **X<sub>fake</sub>** and recognize all real samples **X**. On the other hand **g** will try to create samples which closely resemble **X** so that **d** is not able to categorize them as fakes.

###### Analogy
Imagine a criminal who is trying to counterfeit famous paintings to later sell them a museum in his town (**Generator**). The museums, on the other hand, have employed an art expert whose salary depends on deciding whether a painting is real or a fake (**Discriminator**. This is a *zero-sum game* setup, i.e. the better the criminal does, the less money the art expert gets; and the better the art expert does in distinguishing between real and fake potraits, the less money the criminal earn. By having this kind of competition, we can ensure both the criminal and the art expert will try their best. If the expert has found a solid way to discriminate, the criminal will change his style until they again pass at which point the expert will again try to improve himself.

###### Training
As described above, the training process is supposed to resemble a *zero-sum game*. ?So the loss functions have to be written in that manner, i.e. "contradictory"?


# add: they are neural networks
# add: we train them in alternating manner
# add. loss functions

#### Basics 3: What is a Deep Convolutional Generative Adversarial Model Model




1. Explain: What is a GAN
    - concept (using an Analogy)
    - theoretical basis
        + equations...
1,2 What do we try to do


??? Related Work and Similar Approaches

1,4 Preprocessing

1,5. Network Structure and Design Choices
Our network architecture is a scaled down version inspired by [Radford et al. (2015)](https://arxiv.org/abs/1511.06434). We do not have such a powerful architecture, since our data has lower dimensionality (64x64, grayscale not rgb). Additionally, we just do not have all the time in the world to train that shit!
The generator first expands the input z_vector of size 100 to a vector of length 512x4x4 and reshapes this vector into a 512x4x4 matrix. It then expands the 4x4 feature maps via four [transposed convolutions](https://arxiv.org/abs/1603.07285) with stride 2, a 5x5 kernel size and decreasing amount of feature maps to a single 64x64 matrix of depth 1 (grayscale) -> the generated fake image. Except for the final layer, we use batch-normalization after each convolution.
The discriminator mirrors this architecture by convoluting its input four times, reshaping to a 1d-layer and mapping to a single output unit. We're using strides of 2 and 5x5 kernels again. To regulate the capacity with respect to the generator's training progress, we apply dropout after the second and fourth convolution. No batch-normalization is applied in the discriminator.

1,6. Training Procedure
During training, we update the discriminator with mini-batches consisting of 64 randomly picked real images and 64 z_vectors. The generator is updated using the same z_vector batch as well as an additional 64 z_vectors. We use the Adam optimizer with initial learning rates of 0.00005 for the discriminator and 0.0002 for the generator.
The two learning rates are adjusted given the discriminator's accuracy on the fake as well as the real data. We set two thresholds to determine the learning rate adjustment: if either of the discriminator's accuracies is below the first (lower) threshold the discriminator's learning rate is increased slightly and the generator's decreased since the discriminator's classification is considered less informative. If the discriminator's accuracies reach above the second (higher) threshold, we do the opposite, since the discriminator should not get too powerful and the generator gets very informative feedback. In between the thresholds we increase both learning rates, because we can.
The key to success in training a DCGAN is tuning the interplay between generator and discriminator, because one of them gets "ahead". If the discriminator is too powerful, it will classify all the generators image as fake. In the opposite case, the discriminator is fooled every time and hence classifies everything as true. For the generator both cases result in the same situation: it is left with no useful feedback. Both architecture and learning parameters have to be tuned to achieve good results.
The game between discriminator and generator was hard to balance. We were not able to fully eliminate the chance of the network getting "stuck". Our first approach to avoid oscillations was to [leave either the discriminator-update or the generator-update out](http://torch.ch/blog/2015/11/13/gan.html) for one training batch if the accuracies behaved as described above. The interval needs very precise tuning: setting the lower threshold too low results in the discriminator failing and setting the higher threshold too high makes it too powerful. During training, the network eventually "recovers", but a lot of mini-batches are wasted. To still be able to use all batches for both components of our GAN, we instead decided to increase/decrease the learning rate to this update schedule. Limiting the learning rate within a range was required, again to avoid oscillations. The procedure yielded more stable and consistent results and visually clear transitions between sample images (lower learning rate at times).

10 Evaluation and Comparison



# Task Description

# Related Work and Similar Approaches

# Theoretical Basis and used Procedures

# Network Structure and Desgin Choices

# Performance Evaluation and Comparison
